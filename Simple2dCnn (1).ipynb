{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8178a5a-fac5-4d33-9c33-74103eee296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Evaluation index\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131ac484-d0c9-493e-bb0a-9fc8c98785ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X, y), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063c5b65-2022-487c-93d9-b5bb65697e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(X[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837b3702-0026-4800-a48d-3a098902c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Type conversion and Normalization\n",
    "X=X.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X/=255\n",
    "X_test/=255\n",
    "print(X.max())\n",
    "print(X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcab1238-040a-478b-b45e-e82d6a789c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DoBUY\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#one hot Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y.shape) # (60000,)\n",
    "print(y_one_hot.shape) # (60000, 10)\n",
    "print(y_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d185ce27-de51-401c-a429-0851483bb309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28)\n",
      "(12000, 28, 28)\n",
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Tran Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y_one_hot, test_size =0.2)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4361620-0161-4dac-be85-bb89bd4e7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepraring NN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502992fb-acd4-41eb-bb9a-dd78d9010ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FC():\n",
    "    def __init__ (self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "\n",
    "        #Initialize Function\n",
    "        self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        X_reshaped = X.reshape(X.shape[0], -1)\n",
    "        self.A = np.dot(X_reshaped,self.W) + self.B\n",
    "        return self.activation.forward(self.A)\n",
    "    def backward(self, dZ):\n",
    "        dA = self.activation.backward(dZ)\n",
    "        self.dB = np.mean(dA, axis=0)\n",
    "        self.dW = np.dot(self.X.T, dA)/len(self.X)\n",
    "        dZ= np.dot(dA, self.W.T)\n",
    "        #Update\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd946ace-3ea9-4b96-b325-f375748757bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializerConv2d:\n",
    "    def __init__(self, sigma =0.01):\n",
    "        self.sigma = sigma\n",
    "    def W (self, F,C, FH, FW):\n",
    "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
    "    def B(self, F):\n",
    "        return np.zeros(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2eb6c0b-a4db-4d0d-a3eb-8145e287bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "    def B(self, n_nodes2):\n",
    "        return np.zeros(n_nodes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b965fb85-ba0c-4ec3-a21c-a1fdca702181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitialzier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        return np.random.randn(n_nodes1, n_nodes2)*np.sqrt(2/n_nodes1)\n",
    "    def B(self,n_nodes2):\n",
    "        return np.zeros(n_nodes2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66502bec-e7bb-473b-8870-fa22865e7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8967a74e-3e40-415c-80a8-eca09a2e7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr =lr\n",
    "    def update(self, layer):\n",
    "        layer.W -= self.lr*layer.dW\n",
    "        layer.B -= self.lr*layer.dB\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3f58e7-00df-474e-9148-ddace319e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.hW = 0\n",
    "        self.hB = 0\n",
    "    def update(self,layer):\n",
    "        self.hW += layer.dW*layer.dW\n",
    "        self.hB = layer.dB*layer.dB\n",
    "\n",
    "        layer.W -= self.lr*layer.dW/(np.sqrt(self.hW)+1e-7)\n",
    "        layer.B -= self.lr*layer.dB/(np.sqrt(self.hB)+1e-7)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85b6e7d8-8955-4cd7-b649-b7c025dc40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self, A=None):\n",
    "        self.A = A\n",
    "\n",
    "    def forward(self, Z):\n",
    "        self.A = np.maximum(0, Z)\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        dZ = np.where(self.A > 0, dA, 0)\n",
    "        return dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "237bcf4a-d5a0-4a78-96a9-69b694fbc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class ReLU():\n",
    "   # def __init__(self,A):\n",
    "       # pass\n",
    "    #def forward(self, A):\n",
    "        #self.A = A\n",
    "        #return np.maximum(self.A,0)\n",
    "   # def backward(self,dZ):\n",
    "        #return np.where(self.A>0, dZ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e8734e6-bd7f-4660-821d-dfe853b353b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward (self, A):\n",
    "        return np.exp(A-np.max(A))/np.sum(np.exp(A-np.max(A)), axis-1, keepdims=True)\n",
    "    def backward(self,dZ):\n",
    "        return dZ\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7660d62-c265-4606-bc0d-4d42426d687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    def __init__(self, X,y, batch_size =20, seed=None):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int64)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1212e66-5d01-4438-bdf9-4980cc154980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv2d():\n",
    "    def __init__(self, F,C,FH,FW,P,S, initializer=None, optimizer=None, activation=None):\n",
    "        self.P = P\n",
    "        self.S =S\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "\n",
    "        #Initialize\n",
    "        self.W = self.initializer.W(F,C,FH,FW)\n",
    "        self.B = self.initializer.B(F)\n",
    "    def output_shape2d(self, H,W,PH,PW,FH,FW,SH,SW):\n",
    "        OH = (H + 2*PH -FH)/SH +1\n",
    "        OW =(W +2*PW -FW)/SW +1\n",
    "        return int(OH), int(OW)\n",
    "    def forward(self,X):\n",
    "        self. X = X\n",
    "        N,C,H,W = self.X.shape\n",
    "        F,C,FH,FW = self.W.shape\n",
    "        OH,OW = self.output_shape2d(H,W,self.P, self.P, FH, FW, self.S, self.S)\n",
    "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
    "        A = np.zeros([N,F,OH,OW])\n",
    "        self.X_pad = np.pad(self.X,((0,0), (0,0), (self.P, self.P),(self.P,self.P)))\n",
    "\n",
    "        for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(0,H,self.S):\n",
    "                    for col in range(0,W,self.S):\n",
    "                        A[n,ch,row,col] = \\\n",
    "                        np.sum(self.X_pad[n,:, row:row+FH, col:col+FW]\n",
    "                               *self.W[ch,:,:,:]) \\\n",
    "                        +self.B[ch]\n",
    "            return self.activation.forward(A)\n",
    "    def backward(self, dZ):\n",
    "        dA =self.activation.backward(dZ)\n",
    "        N,C,H,F,FH,FW,OH,OW = self. params\n",
    "        dZ = np.zeros(self.X_pad.shape)\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.dB = np.zeros(self.B.shape)\n",
    "\n",
    "\n",
    "        for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(0,H, self.S):\n",
    "                    for col in range (0,W,self.S):\n",
    "                        dZ [n,:, row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
    "        d1_rows = range(self.P), range(H+self.P, H+2*self.P,1)\n",
    "        d1_cols = range(self.P), range(W+self.P, W+2*self.P,1)\n",
    "\n",
    "        dZ = np.delete(dZ, d1_rows, axis=2)\n",
    "        dZ = np.delete(dZ, d1_cols, axis=3)\n",
    "\n",
    "        for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(OH):\n",
    "                    for col in range (OW):\n",
    "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH, col:col+FW]\n",
    "            #output channels\n",
    "        for ch in range(F):\n",
    "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "\n",
    "            self = self.optimizer.update(self)\n",
    "            return dZ\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec92dd4-dc68-416d-951f-872d2a54cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_shape2d(IH=5, IW=5, PH=0, PW=0, FH=3, FW=3, SH=1, SW=1):\n",
    "    OH  = (IH +2*PH -FH)/SH +1\n",
    "    OW= (IW+2*PW -FW)/SW +1\n",
    "    return int(OH), int(OW)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72d7cfdd-5aa4-4ae9-8c32-2c000ada804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(output_shape2d(IH=6, IW=6, PH=0, PW=0, FH=3, FW=3, SH=1, SW=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b655adc9-f88a-4dfb-af77-bcb9d4d42f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape: (5, 4, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "N,C,H,W = (5,1,28,28)\n",
    "F,C,FH,FW = (4,1,3,3)\n",
    "\n",
    "S=1\n",
    "P =1\n",
    "\n",
    "OH, OW = output_shape2d(H,W,P,P,FH,FW,S,S)\n",
    "A = np.zeros([N,F,OH,OW])\n",
    "\n",
    "X_sample = X[0:N].reshape(N,C,H,W)\n",
    "X_pad = np.pad(X_sample,((0,0), (0,0), (P,P),(P,P)))\n",
    "w = np.ones([F,C,FH,FW])\n",
    "B = np.ones(F)\n",
    "\n",
    "for n in range(N):\n",
    "    for ch in range(F):\n",
    "        for row in range(0, H,S):\n",
    "            for col in range(0,W,S):\n",
    "                A[n,ch,row,col] = \\\n",
    "                np.sum(X_pad[n,:,row:row+FH, col:col+FW]*w[ch,:,:,:]) +B[ch]\n",
    "print('A.shape:', A.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313f36a0-7657-4668-b626-415483752d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dZ.shape: (5, 1, 28, 28)\n",
      "dW.shape: (4, 1, 3, 3)\n",
      "dB.shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "dA = np.ones(A.shape)\n",
    "dZ = np.zeros(X_pad.shape)\n",
    "dW = np.zeros(w.shape)\n",
    "dB = np.zeros(B.shape)\n",
    "\n",
    "for n in range(N):\n",
    "    for ch in range(F):\n",
    "        for row in range(0,H,S):\n",
    "            for col in range (0,W,S):\n",
    "                dZ[n,:, row:row+FH,col:col+FW] += dA[n,ch,row,col]*w[ch,:,:,:]\n",
    "d1_rows = range(P), range(H+P, H+2*P,1)\n",
    "d1_cols = range(P), range(W+P, W+2*P,1)\n",
    "\n",
    "dZ = np.delete(dZ, d1_rows, axis=2)\n",
    "dZ = np.delete(dZ, d1_cols, axis=3)\n",
    "for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(OH):\n",
    "                    for col in range (OW):\n",
    "                        dW[ch,:,:,:] += dA[n,ch,row,col]*X_pad[n,:,row:row+FH, col:col+FW]\n",
    "            #output channels\n",
    "for ch in range(F):\n",
    "    dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "print('dZ.shape:', dZ.shape)\n",
    "print('dW.shape:', dW.shape)\n",
    "print('dB.shape:', dB.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af416c62-bd9c-4517-b356-bc948c6c736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[4 6 5 5 0 6]\n",
      "   [6 7 5 5 0 2]\n",
      "   [1 4 1 8 8 7]\n",
      "   [2 3 1 0 3 2]\n",
      "   [2 8 3 4 3 7]\n",
      "   [2 8 2 2 1 1]]]]\n",
      "(1, 1, 3, 3)\n",
      "[[[[7. 5. 6.]\n",
      "   [4. 8. 8.]\n",
      "   [8. 4. 7.]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MaxPool2D:\n",
    "    def __init__(self, P=2):\n",
    "        self.P = P\n",
    "        self.PA = None\n",
    "        self.Pindex = None\n",
    "\n",
    "    def forward(self, A):\n",
    "        N, C, H, W = A.shape\n",
    "        PS = self.P\n",
    "        PH = H // PS\n",
    "        PW = W // PS\n",
    "        \n",
    "        self.PA = np.zeros((N, C, PH, PW))\n",
    "        self.Pindex = np.zeros((N, C, PH, PW), dtype=int)\n",
    "        \n",
    "        for n in range(N):\n",
    "            for ch in range(C):\n",
    "                for row in range(PH):\n",
    "                    for col in range(PW):\n",
    "                        # Calculate the indices for pooling window\n",
    "                        start_row, start_col = row*PS, col*PS\n",
    "                        end_row, end_col = start_row+PS, start_col+PS\n",
    "                        \n",
    "                        # Ensure indices are within bounds of the input array\n",
    "                        end_row = min(end_row, H)\n",
    "                        end_col = min(end_col, W)\n",
    "                        \n",
    "                        # Perform pooling only if the window is within bounds\n",
    "                        if start_row < H and start_col < W:\n",
    "                            window = A[n, ch, start_row:end_row, start_col:end_col]\n",
    "                            \n",
    "                            # Calculate maximum value within the pooling window\n",
    "                            self.PA[n, ch, row, col] = np.max(window)\n",
    "                            # Record the index of the maximum value\n",
    "                            self.Pindex[n, ch, row, col] = np.argmax(window)\n",
    "\n",
    "        return self.PA\n",
    "    def backward(self, dA):\n",
    "        N, C, PH, PW = dA.shape\n",
    "        PS = self.P\n",
    "        dA_prev = np.zeros_like(self.PA)\n",
    "    \n",
    "        for n in range(N):\n",
    "            for ch in range(C):\n",
    "                for row in range(PH):\n",
    "                    for col in range(PW):\n",
    "                        index = self.Pindex[n, ch, row, col]\n",
    "                        # Calculate the row and column indices in dA_prev\n",
    "                        dA_row = row*PS + index // PS\n",
    "                        dA_col = col*PS + index % PS\n",
    "                        # Check if the calculated indices are within the bounds of dA_prev\n",
    "                        if dA_row < dA_prev.shape[2] and dA_col < dA_prev.shape[3]:\n",
    "                            dA_prev[n, ch, dA_row, dA_col] += dA[n, ch, row, col]\n",
    "        \n",
    "        return dA_prev\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
    "print(X)\n",
    "Pooling = MaxPool2D(P=2)\n",
    "A = Pooling.forward(X)\n",
    "print(A.shape)\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1288b55-51a4-4fcc-9ac1-b5b437ad02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[3, 0, 1],\n",
       "         [1, 1, 0],\n",
       "         [1, 1, 1]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pooling.Pindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b9b7e0b-7216-4bf2-87d7-85e81cbec8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[3 0 4]\n",
      "   [6 6 3]\n",
      "   [5 8 4]]]]\n"
     ]
    }
   ],
   "source": [
    "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
    "print(dA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4327bfc9-3660-45ed-afe0-ca46fa3a46ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0.]\n",
      "   [0. 3. 0.]\n",
      "   [0. 6. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "dZ = Pooling.backward(dA)\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0045a829-7d1c-4c69-b3bc-6771e4279b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(len(X), -1)\n",
    "    def backward(self, X):\n",
    "        return X.reshape(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb178b7a-5051-43d4-b9b3-1c979cd6cb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foward_shape: (20, 50)\n",
      "Backward_shape: (20, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "TEST = np.zeros([20,2,5,5])\n",
    "flt = Flatten()\n",
    "flat_forward = flt.forward(TEST)\n",
    "print('Foward_shape:', flat_forward.shape)\n",
    "print('Backward_shape:', flt.backward(flat_forward).shape)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7830907c-6583-44ca-a9d0-66a0416f328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM 7 TRAINING AND ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "142922c7-322e-4214-a73f-5ba9eacdaaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch2dCNNClassifier():\n",
    "    def __init__(self, NN, CNN, n_epochs=5, n_batch=1, verbose = False):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_batch = n_batch\n",
    "        self.verbose = verbose\n",
    "        self.log_loss = np.zeros(self.n_epochs)\n",
    "        self.log_acc = np.zeros(self.n_epochs)\n",
    "        self.NN=NN\n",
    "        self.CNN = CNN\n",
    "    def loss_function(self, y,yt):\n",
    "        delta = 1e-7\n",
    "        return -np,mean(yt*np.log(y+delta))\n",
    "    def accuracy(self, Z,Y):\n",
    "        return accuracy_score(Y, Z)\n",
    "    def fit(self, X,y, X_val=False, y_val=False):\n",
    "        for epoch in range(self.n_epochs):\n",
    "            get_mini_batch = GetMiniBatch(X,y, batch_size = self.n_batch)\n",
    "\n",
    "            self.loss =0\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                forward_data = mini_X_train[:,np.newaxis,:,:]\n",
    "                #conv\n",
    "                for layer in range(len(self.CNN)):\n",
    "                    forward_data = self.CNN[layer].forward(forward_data)\n",
    "                #flatten\n",
    "                flt = Flatten()\n",
    "                forward_data = flt.forward(forward_data)\n",
    "                #NN\n",
    "                for layer in range(len(self.NN)):\n",
    "                    forward_data = self.NN[layer].forward(forward_data)\n",
    "                Z=forward_data\n",
    "                #Backward propagation\n",
    "                backward_data = (Z - mini_y_train)/self.n_batch\n",
    "                for layer in range(len(self.NN)-1,-1,-1):\n",
    "                    backward_data = self.NN[layer].backward(backward_data)\n",
    "                backward_data = flt.backward(backward_data)\n",
    "                for layer in range(len(self.CNN),-1,-1,-1):\n",
    "                    backward_data = self.CNN[layer].backward(backward_data)\n",
    "                #loss function\n",
    "                self.loss += self.loss_fuction(Z,mini_y_train)\n",
    "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
    "            self.log_acc[epoch] = self.accuracy(self.predict(X), np.argmax(y,axis=1))\n",
    "    def predict(self, X):\n",
    "        pred_data = X[:,np.newaxis, :,:]\n",
    "        #Conv\n",
    "        for layer in range(len(self.CNN)):\n",
    "            pred_data = self.CNN[layer].forward(pred_data)\n",
    "        flt = Flatten()\n",
    "        pred_data = flt.forward(pred_data)\n",
    "        #NN\n",
    "        for layer in range(len(self.NN)):\n",
    "            pred_data = self.NN[layer].forward(pred_data)\n",
    "        return np.argmax(pred_data, axis=1)\n",
    "        \n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cf44ec8-c466-43b1-86c5-70d82cd81823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All bonding layers\n",
    "NN = {0:FC(784, 400, HeInitialzier(), AdaGrad(0.01), ReLU()),\n",
    "      1:FC(400, 200, HeInitialzier(), AdaGrad(0.01), ReLU()),\n",
    "      2:FC(200,10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b907fdd-c3ac-421c-90ba-bec25112d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = {0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1, S=1,\n",
    "                      initializer = SimpleInitializerConv2d(),\n",
    "                      optimizer =SGD(),\n",
    "                      activation =ReLU())\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a8d39cc-ff8c-4d7a-a38e-a9b6cd59719c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200,7840) and (784,400) not aligned: 7840 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cnn1 \u001b[38;5;241m=\u001b[39m Scratch2dCNNClassifier(NN\u001b[38;5;241m=\u001b[39mNN, CNN\u001b[38;5;241m=\u001b[39mCNN, n_epochs \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_batch \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m cnn1\u001b[38;5;241m.\u001b[39mfit(X_train[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1000\u001b[39m], y_train[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1000\u001b[39m])\n",
      "Cell \u001b[1;32mIn[31], line 30\u001b[0m, in \u001b[0;36mScratch2dCNNClassifier.fit\u001b[1;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#NN\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNN)):\n\u001b[1;32m---> 30\u001b[0m     forward_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNN[layer]\u001b[38;5;241m.\u001b[39mforward(forward_data)\n\u001b[0;32m     31\u001b[0m Z\u001b[38;5;241m=\u001b[39mforward_data\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#Backward propagation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m, in \u001b[0;36mFC.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m     14\u001b[0m X_reshaped \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_reshaped,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (200,7840) and (784,400) not aligned: 7840 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "cnn1 = Scratch2dCNNClassifier(NN=NN, CNN=CNN, n_epochs =10, n_batch =200, verbose = False)\n",
    "cnn1.fit(X_train[0:1000], y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809db640-a216-4e22-955b-1be63d99a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate\n",
    "y_pred = cnn1.predict(X_valid[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f132fb0-acaf-4992-a359-25bd638ea43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
